{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6db46434",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T15:52:30.866670Z",
     "start_time": "2025-12-29T15:52:30.863845Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize, Bounds\n",
    "from hypernet_MLP import Hypernet_MLP\n",
    "from hypernet_trans import Hypernet_trans\n",
    "from functions_hv_python3 import HyperVolume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6ba3f98e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T15:52:30.874879Z",
     "start_time": "2025-12-29T15:52:30.868574Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=702):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "\n",
    "set_seed(702)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c0fe6fdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T15:52:30.877739Z",
     "start_time": "2025-12-29T15:52:30.876179Z"
    }
   },
   "outputs": [],
   "source": [
    "case = case = \"_Ex_7_2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf49fd4",
   "metadata": {},
   "source": [
    "# Const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d6ef3e46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T15:52:30.881322Z",
     "start_time": "2025-12-29T15:52:30.879168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419d020d",
   "metadata": {},
   "source": [
    "# Def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a40976c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T15:52:30.886991Z",
     "start_time": "2025-12-29T15:52:30.882392Z"
    }
   },
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from scipy.optimize import minimize            \n",
    "        \n",
    "class Projection:\n",
    "    def __init__(self, cons, bounds, dim, proj_type='euclid'):\n",
    "        self.cons = cons\n",
    "        self.bounds = bounds\n",
    "        self.dim = dim\n",
    "        self.proj_type = proj_type\n",
    "        \n",
    "        if self.proj_type == 'qplus':\n",
    "            self.objective_func = self._obj_positive_diff\n",
    "        elif self.proj_type == 'euclid':\n",
    "            self.objective_func = self._obj_l2_norm\n",
    "        else:\n",
    "            print(f\"Ph√©p chi·∫øu {self.objective_func} kh√¥ng c√†i ƒë·∫∑t, ch·ªçn 'qplus' ho·∫∑c 'euclid'\")\n",
    "\n",
    "    def _obj_l2_norm(self, x, y):\n",
    "        return np.sqrt(np.sum((x - y)**2))\n",
    "    \n",
    "    def _obj_positive_diff(self, x, y):\n",
    "        v = np.maximum(y - x, 0) \n",
    "        return np.sum(v**2)\n",
    "\n",
    "    def project(self, target_point):\n",
    "        init_point = np.random.rand(1, self.dim).tolist()[0]\n",
    "        \n",
    "        res = minimize(\n",
    "            self.objective_func,\n",
    "            init_point,\n",
    "            args=(target_point, ),\n",
    "            constraints=self.cons,\n",
    "            bounds=self.bounds,\n",
    "            options={'disp': False}\n",
    "        )\n",
    "        \n",
    "        optim_point = res.x\n",
    "        \n",
    "        if self.proj_type == 'qplus':\n",
    "            return target_point - np.maximum(target_point - optim_point, 0)\n",
    "        else:\n",
    "            return optim_point\n",
    "\n",
    "class Problem():\n",
    "    def __init__(self, f, dim_x, dim_y, proj_C, proj_Qplus):\n",
    "        self.f = f\n",
    "        self.dim_x = dim_x\n",
    "        self.dim_y = dim_y\n",
    "        self.proj_C = proj_C\n",
    "        self.proj_Qplus = proj_Qplus\n",
    "    \n",
    "    def objective_func(self, x):\n",
    "        vals = [func(x) for func in self.f]\n",
    "        return np.concatenate(vals)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5d6f3d28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T15:52:30.892715Z",
     "start_time": "2025-12-29T15:52:30.888353Z"
    }
   },
   "outputs": [],
   "source": [
    "def f1(x):    return (x[0]**2 + x[1]**2)/50\n",
    "def f2(x):    return ((x[0] - 5)**2 + (x[1] - 5)**2)/50\n",
    "def f(x):    return np.array([\n",
    "    (x[0]**2 + x[1]**2)/50,\n",
    "    ((x[0] - 5)**2 + (x[1] - 5)**2)/50])\n",
    "#--------------- C --------------------#\n",
    "bounds_x = Bounds([0,0],[5, 5])\n",
    "\n",
    "#--------------- Q --------------------#\n",
    "def q1(y):    return 0.2**2 - (y[0] - 0.4)**2 - (y[1] - 0.4)**2\n",
    "\n",
    "def q_plus(y):\n",
    "    center = 0.4\n",
    "    radius_sq = 0.2**2  \n",
    "    dx = np.maximum(0, y[0] - center)\n",
    "    dy = np.maximum(0, y[1] - center)\n",
    "    return radius_sq - (dx**2 + dy**2)\n",
    "# H√†m d√πng cho Projection \n",
    "cons_C = ()\n",
    "dim_x = 2\n",
    "cons_Q = ({'type': 'ineq', 'fun' : q1,},)\n",
    "cons_Qplus = ({'type': 'ineq', 'fun': q_plus},)\n",
    "dim_y = 2\n",
    "# Setup Projections\n",
    "proj_C_handler = Projection(cons=cons_C, bounds=bounds_x, dim=dim_x, proj_type='euclid')\n",
    "proj_Q_handler = Projection(cons=cons_Q, bounds=None, dim=dim_y, proj_type='qplus')\n",
    "# Setup Problem\n",
    "prob = Problem(\n",
    "    f=[f1, f2], \n",
    "    dim_x=dim_x, dim_y=dim_y,\n",
    "    proj_C=proj_C_handler.project,\n",
    "    proj_Qplus=proj_Q_handler.project\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6cc3790d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T15:52:30.903158Z",
     "start_time": "2025-12-29T15:52:30.894252Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_objectives_single(functions, x_tensor):\n",
    "    \"\"\"\n",
    "    H√†m ph·ª• tr·ª£: T√≠nh gi√° tr·ªã f1(x), f2(x) cho 1 m·∫´u x duy nh·∫•t.\n",
    "    \"\"\"\n",
    "    vals = []\n",
    "    for func in functions:\n",
    "        val = func(x_tensor)\n",
    "        if not torch.is_tensor(val):\n",
    "            val = torch.tensor(val, dtype=torch.float32)\n",
    "        vals.append(val)\n",
    "    return torch.stack(vals).reshape(-1)\n",
    "\n",
    "def train_hypernet(hypernet, prob, z_star, \n",
    "                   num_epochs=1000, \n",
    "                   lr=1e-3, \n",
    "                   num_partitions=100, \n",
    "                   lr_step_size=300, \n",
    "                   lr_gamma=0.5,\n",
    "                   # --- THAM S·ªê THU·∫¨T TO√ÅN 2-A (Monotonic Penalty) ---\n",
    "                   # C·∫£ hai ƒë·ªÅu TƒÇNG d·∫ßn ƒë·ªÉ ƒë·∫£m b·∫£o Feasibility\n",
    "                   beta_C_0=1.0,    # Gi√° tr·ªã kh·ªüi t·∫°o cho C\n",
    "                   beta_C_max=1000.0, # Gi√° tr·ªã t·ªëi ƒëa cho C\n",
    "                   rho_C=1.01,      # T·ª∑ l·ªá tƒÉng cho C (VD: 1.01 = +1%/step)\n",
    "                   \n",
    "                   beta_Q_0=1.0,    # Gi√° tr·ªã kh·ªüi t·∫°o cho Q (Algorithm 2-A: TƒÉng Q)\n",
    "                   beta_Q_max=1000.0, # Gi√° tr·ªã t·ªëi ƒëa cho Q\n",
    "                   rho_Q=1.01,      # T·ª∑ l·ªá tƒÉng cho Q\n",
    "                   verbose=True): \n",
    "    \n",
    "    # 1. Kh·ªüi t·∫°o\n",
    "    optimizer = optim.Adam(hypernet.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=lr_step_size, gamma=lr_gamma)\n",
    "    \n",
    "    # ƒê·∫£m b·∫£o z_star chu·∫©n shape\n",
    "    z_star_tensor = torch.tensor(z_star, dtype=torch.float32).view(1, -1)\n",
    "    \n",
    "    # Kh·ªüi t·∫°o h·ªá s·ªë ph·∫°t (Step 1 c·ªßa Alg 2-A)\n",
    "    beta_C = beta_C_0\n",
    "    beta_Q = beta_Q_0\n",
    "    \n",
    "    angle_step = (math.pi / 2) / num_partitions\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"=== TRAIN HYPERNET (Algorithm 2-A: Monotonic Penalty) ===\")\n",
    "        print(f\"Constraint C: Start {beta_C_0} -> Max {beta_C_max} (Rate {rho_C})\")\n",
    "        print(f\"Constraint Q: Start {beta_Q_0} -> Max {beta_Q_max} (Rate {rho_Q})\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        hypernet.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # --------------------------------------------------------\n",
    "        # 1. L·∫•y m·∫´u ph√¢n t·∫ßng (Stratified Sampling - Step 4,5 of Alg 2-A)\n",
    "        # --------------------------------------------------------\n",
    "        starts = torch.arange(num_partitions) * angle_step\n",
    "        noise = torch.rand(num_partitions) * angle_step\n",
    "        thetas = starts + noise \n",
    "        \n",
    "        r_batch_np = np.stack([np.cos(thetas.numpy()), np.sin(thetas.numpy())], axis=1)\n",
    "        r_tensor_batch = torch.tensor(r_batch_np, dtype=torch.float32)\n",
    "        \n",
    "        # --------------------------------------------------------\n",
    "        # 2. Lan truy·ªÅn xu√¥i & T√≠nh Loss (Step 8-18 of Alg 2-A)\n",
    "        # --------------------------------------------------------\n",
    "        \n",
    "        # Forward pass (Sequential ƒë·ªÉ tr√°nh l·ªói shape c·ªßa Hypernet)\n",
    "        x_pred_list = []\n",
    "        for i in range(num_partitions):\n",
    "            r_single = r_tensor_batch[i].unsqueeze(0)\n",
    "            x_single = hypernet(r_single)\n",
    "            x_pred_list.append(x_single)\n",
    "            \n",
    "        x_vec_batch = torch.cat(x_pred_list, dim=0) # Batch output\n",
    "        \n",
    "        # Loop t√≠nh Loss th√†nh ph·∫ßn (do Scipy projection kh√¥ng h·ªó tr·ª£ batch)\n",
    "        x_np_batch = x_vec_batch.detach().cpu().numpy()\n",
    "        loss_C_list = []\n",
    "        loss_Q_list = []\n",
    "        y_pred_list = []\n",
    "        \n",
    "        for i in range(num_partitions):\n",
    "            x_i_tensor = x_vec_batch[i].reshape(-1) \n",
    "            x_i_np = x_i_tensor.detach().cpu().numpy()\n",
    "            \n",
    "            # a. Loss C: ||x - P_C(x)||^2\n",
    "            x_proj_i_np = prob.proj_C(x_i_np)\n",
    "            x_proj_i_tensor = torch.tensor(x_proj_i_np, dtype=torch.float32)\n",
    "            loss_C_list.append(torch.sum((x_i_tensor - x_proj_i_tensor)**2))\n",
    "            \n",
    "            # b. F(x)\n",
    "            y_pred_i = evaluate_objectives_single(prob.f, x_i_tensor)\n",
    "            y_pred_list.append(y_pred_i)\n",
    "            \n",
    "            # c. Loss Q: ||y - P_Q+(y)||^2\n",
    "            y_i_np = y_pred_i.detach().cpu().numpy()\n",
    "            y_proj_i_np = prob.proj_Qplus(y_i_np)\n",
    "            y_proj_i_tensor = torch.tensor(y_proj_i_np, dtype=torch.float32)\n",
    "            loss_Q_list.append(torch.sum((y_pred_i - y_proj_i_tensor)**2))\n",
    "        \n",
    "        # T√≠nh trung b√¨nh Loss (Mean L_C, Mean L_Q)\n",
    "        y_pred_batch = torch.stack(y_pred_list)\n",
    "        L_bar_C = torch.mean(torch.stack(loss_C_list))\n",
    "        L_bar_Q = torch.mean(torch.stack(loss_Q_list))\n",
    "        \n",
    "        # --------------------------------------------------------\n",
    "        # 3. T√≠nh Loss M·ª•c ti√™u Chebyshev (Step 20-21 of Alg 2-A)\n",
    "        # --------------------------------------------------------\n",
    "        diff = y_pred_batch - z_star_tensor\n",
    "        weighted_diff = r_tensor_batch * diff\n",
    "        max_vals, _ = torch.max(weighted_diff, dim=1)\n",
    "        L_Obj = torch.mean(max_vals)\n",
    "        \n",
    "        # --------------------------------------------------------\n",
    "        # 4. T·ªïng h·ª£p v√† C·∫≠p nh·∫≠t (Step 24-27 of Alg 2-A)\n",
    "        # --------------------------------------------------------\n",
    "        # L_Total = L_Obj + Œ≤_C * L_C + Œ≤_Q * L_Q\n",
    "        total_loss = L_Obj + (beta_C * L_bar_C) + (beta_Q * L_bar_Q)\n",
    "        \n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # --------------------------------------------------------\n",
    "        # 5. C·∫≠p nh·∫≠t h·ªá s·ªë Ph·∫°t (Step 30-31 of Alg 2-A)\n",
    "        # --------------------------------------------------------\n",
    "        # C·∫£ hai h·ªá s·ªë ƒë·ªÅu TƒÇNG d·∫ßn\n",
    "        beta_C = min(beta_C_max, beta_C * rho_C)\n",
    "        beta_Q = min(beta_Q_max, beta_Q * rho_Q)\n",
    "        \n",
    "        # Logging\n",
    "        if verbose and epoch % 100 == 0:\n",
    "            current_lr = scheduler.get_last_lr()[0]\n",
    "            print(f\"Epoch {epoch}: Total={total_loss.item():.3f} \"\n",
    "                  f\"(Obj={L_Obj.item():.4f}, C={L_bar_C.item():.5f}, Q={L_bar_Q.item():.5f}) \"\n",
    "                  f\"|| BetaC={beta_C:.1f}, BetaQ={beta_Q:.1f}\")\n",
    "            \n",
    "    return hypernet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f1a1fc1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T15:52:30.909067Z",
     "start_time": "2025-12-29T15:52:30.904660Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_med(pf_pred, pf_true):\n",
    "    \"\"\"T√≠nh Mean Error Distance (Euclidean)\"\"\"\n",
    "    pf_pred = np.array(pf_pred)\n",
    "    pf_true = np.array(pf_true)\n",
    "    if pf_pred.shape != pf_true.shape:\n",
    "        return np.inf\n",
    "    distances = np.linalg.norm(pf_pred - pf_true, axis=1)\n",
    "    return np.mean(distances)\n",
    "def calculate_hv_score(pareto_f, prob, ref_point):\n",
    "    \"\"\"T√≠nh Hypervolume, lo·∫°i b·ªè ƒëi·ªÉm vi ph·∫°m r√†ng bu·ªôc Q+\"\"\"\n",
    "    valid_points = []\n",
    "    tol = 1e-3\n",
    "    for point in pareto_f:\n",
    "        # Ki·ªÉm tra feasibility v·ªõi Q+\n",
    "        point_proj = prob.proj_Qplus(point)\n",
    "        dist_Q = np.linalg.norm(point - point_proj)\n",
    "        \n",
    "        # Ki·ªÉm tra n·∫±m trong v√πng Reference\n",
    "        is_dominated_by_ref = np.all(point < ref_point)\n",
    "        \n",
    "        if dist_Q < tol and is_dominated_by_ref:\n",
    "            valid_points.append(point.tolist())\n",
    "            \n",
    "    if len(valid_points) < 2: return 0.0\n",
    "    \n",
    "    hv = HyperVolume(ref_point)\n",
    "    return hv.compute(valid_points)\n",
    "\n",
    "def evaluate_model_all(hypernet, prob, test_rays, pf_true, ref_point):\n",
    "    \"\"\"\n",
    "    ƒê√°nh gi√° model m·ªôt l·∫ßn duy nh·∫•t cho c·∫£ MED v√† HV.\n",
    "    \"\"\"\n",
    "    hypernet.eval()\n",
    "    pf_pred = []\n",
    "    rays_tensor = torch.tensor(test_rays, dtype=torch.float32, device=device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(len(rays_tensor)):\n",
    "            r_single = rays_tensor[i].unsqueeze(0)\n",
    "            x_raw = hypernet(r_single).squeeze().cpu().numpy()\n",
    "            \n",
    "            # Chi·∫øu l√™n C ƒë·ªÉ ƒë·∫£m b·∫£o x h·ª£p l·ªá\n",
    "            x_proj = prob.proj_C(x_raw)\n",
    "            \n",
    "            # T√≠nh f(x)\n",
    "            val = [func(x_proj) for func in prob.f]\n",
    "            pf_pred.append(val)\n",
    "        \n",
    "            \n",
    "    pf_pred = np.array(pf_pred)\n",
    "    \n",
    "    # T√≠nh c√°c ch·ªâ s·ªë\n",
    "    med_score = calculate_med(pf_pred, pf_true)\n",
    "    hv_score = calculate_hv_score(pf_pred, prob, ref_point)\n",
    "    \n",
    "    return med_score, hv_score, pf_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6563764",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d696f100",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T15:52:30.916180Z",
     "start_time": "2025-12-29T15:52:30.910185Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'lr': [1e-3, 5e-4],\n",
    "    'num_epochs': [500, 1000, 2000],\n",
    "    \n",
    "    'num_partitions': [20],\n",
    "    \n",
    "    # Tham s·ªë thu·∫≠t to√°n 2-A: TƒÉng d·∫ßn penalty\n",
    "    'beta_C_0': [10],\n",
    "    'beta_Q_0': [5],\n",
    "    'rho_C': [1.03], \n",
    "    'rho_Q': [1.01, 1.03],\n",
    "    \n",
    "    # C·ªë ƒë·ªãnh Max ƒë·ªÉ tr√°nh grid qu√° l·ªõn \n",
    "    'beta_C_max': [1000.0],\n",
    "    'beta_Q_max': [100.0, 500.0, 1000.0]\n",
    "}\n",
    "\n",
    "z_star = np.array([0.0374, 0.0374])\n",
    "ref_point = np.array([1.3927, 1.3927])\n",
    "\n",
    "config_path='../4_Pareto_front/config.yaml'\n",
    "with open(config_path, 'r') as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "test_rays = np.array(cfg['data']['test_ray'])\n",
    "pf_true = np.load(f\"../4_Pareto_front/test/{case}/pf_dynamic_true.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f727817a",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "13f1aaf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T15:52:30.919671Z",
     "start_time": "2025-12-29T15:52:30.917804Z"
    }
   },
   "outputs": [],
   "source": [
    "models = [\"trans\", \"MLP\"]\n",
    "INDICATOR = \"MED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d7db2140",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T15:52:30.922829Z",
     "start_time": "2025-12-29T15:52:30.920977Z"
    }
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "best_scores_tracker = {}\n",
    "save_dir = f\"model/{case}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e51f15b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-12-29T15:52:30.875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ ƒêang train Model: trans | ∆Øu ti√™n: MED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   >>> Config 1/36: {'lr': 0.001, 'num_epochs': 500, 'num_partitions': 20, 'beta_C_0': 10, 'beta_Q_0': 5, 'rho_C': 1.03, 'rho_Q': 1.01, 'beta_C_max': 1000.0, 'beta_Q_max': 100.0}\n",
      "=== TRAIN HYPERNET (Algorithm 2-A: Monotonic Penalty) ===\n",
      "Constraint C: Start 10 -> Max 1000.0 (Rate 1.03)\n",
      "Constraint Q: Start 5 -> Max 100.0 (Rate 1.01)\n",
      "Epoch 0: Total=1.232 (Obj=0.5886, C=0.00039, Q=0.12785) || BetaC=10.3, BetaQ=5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2312\\519494600.py:28: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
      "  res = minimize(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: Total=0.121 (Obj=0.1206, C=0.00000, Q=0.00000) || BetaC=198.0, BetaQ=13.7\n",
      "Epoch 200: Total=0.111 (Obj=0.1111, C=0.00000, Q=0.00000) || BetaC=1000.0, BetaQ=36.9\n",
      "Epoch 300: Total=0.110 (Obj=0.1095, C=0.00000, Q=0.00000) || BetaC=1000.0, BetaQ=99.9\n",
      "Epoch 400: Total=0.110 (Obj=0.1096, C=0.00000, Q=0.00000) || BetaC=1000.0, BetaQ=100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [01:06, 67.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ‚è±Ô∏è Time: 66.9s | üìè MED: 0.008264 | üìà HV: 1.666971\n",
      "      üèÜ New Best MED Found! Saved to: model/_Ex_7_2/best_trans_MED.pth\n",
      "\n",
      "   >>> Config 2/36: {'lr': 0.001, 'num_epochs': 500, 'num_partitions': 20, 'beta_C_0': 10, 'beta_Q_0': 5, 'rho_C': 1.03, 'rho_Q': 1.01, 'beta_C_max': 1000.0, 'beta_Q_max': 500.0}\n",
      "=== TRAIN HYPERNET (Algorithm 2-A: Monotonic Penalty) ===\n",
      "Constraint C: Start 10 -> Max 1000.0 (Rate 1.03)\n",
      "Constraint Q: Start 5 -> Max 500.0 (Rate 1.01)\n",
      "Epoch 0: Total=5.900 (Obj=0.7094, C=0.35860, Q=0.32094) || BetaC=10.3, BetaQ=5.0\n",
      "Epoch 100: Total=0.171 (Obj=0.1707, C=0.00000, Q=0.00000) || BetaC=198.0, BetaQ=13.7\n",
      "Epoch 200: Total=0.119 (Obj=0.1192, C=0.00000, Q=0.00000) || BetaC=1000.0, BetaQ=36.9\n",
      "Epoch 300: Total=0.119 (Obj=0.1190, C=0.00000, Q=0.00000) || BetaC=1000.0, BetaQ=99.9\n",
      "Epoch 400: Total=0.119 (Obj=0.1193, C=0.00000, Q=0.00000) || BetaC=1000.0, BetaQ=270.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [02:12, 66.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ‚è±Ô∏è Time: 65.5s | üìè MED: 0.033578 | üìà HV: 1.624628\n",
      "\n",
      "   >>> Config 3/36: {'lr': 0.001, 'num_epochs': 500, 'num_partitions': 20, 'beta_C_0': 10, 'beta_Q_0': 5, 'rho_C': 1.03, 'rho_Q': 1.01, 'beta_C_max': 1000.0, 'beta_Q_max': 1000.0}\n",
      "=== TRAIN HYPERNET (Algorithm 2-A: Monotonic Penalty) ===\n",
      "Constraint C: Start 10 -> Max 1000.0 (Rate 1.03)\n",
      "Constraint Q: Start 5 -> Max 1000.0 (Rate 1.01)\n",
      "Epoch 0: Total=1.521 (Obj=0.6220, C=0.00879, Q=0.16216) || BetaC=10.3, BetaQ=5.0\n",
      "Epoch 100: Total=0.132 (Obj=0.1316, C=0.00000, Q=0.00000) || BetaC=198.0, BetaQ=13.7\n",
      "Epoch 200: Total=0.115 (Obj=0.1151, C=0.00000, Q=0.00000) || BetaC=1000.0, BetaQ=36.9\n",
      "Epoch 300: Total=0.111 (Obj=0.1111, C=0.00000, Q=0.00000) || BetaC=1000.0, BetaQ=99.9\n",
      "Epoch 400: Total=0.109 (Obj=0.1092, C=0.00000, Q=0.00000) || BetaC=1000.0, BetaQ=270.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [03:19, 66.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ‚è±Ô∏è Time: 66.6s | üìè MED: 0.010001 | üìà HV: 1.678037\n",
      "\n",
      "   >>> Config 4/36: {'lr': 0.001, 'num_epochs': 500, 'num_partitions': 20, 'beta_C_0': 10, 'beta_Q_0': 5, 'rho_C': 1.03, 'rho_Q': 1.03, 'beta_C_max': 1000.0, 'beta_Q_max': 100.0}\n",
      "=== TRAIN HYPERNET (Algorithm 2-A: Monotonic Penalty) ===\n",
      "Constraint C: Start 10 -> Max 1000.0 (Rate 1.03)\n",
      "Constraint Q: Start 5 -> Max 100.0 (Rate 1.03)\n",
      "Epoch 0: Total=1.600 (Obj=0.6124, C=0.01493, Q=0.16774) || BetaC=10.3, BetaQ=5.2\n",
      "Epoch 100: Total=0.137 (Obj=0.1370, C=0.00000, Q=0.00000) || BetaC=198.0, BetaQ=99.0\n",
      "Epoch 200: Total=0.119 (Obj=0.1189, C=0.00000, Q=0.00000) || BetaC=1000.0, BetaQ=100.0\n",
      "Epoch 300: Total=0.107 (Obj=0.1068, C=0.00000, Q=0.00000) || BetaC=1000.0, BetaQ=100.0\n",
      "Epoch 400: Total=0.106 (Obj=0.1061, C=0.00000, Q=0.00000) || BetaC=1000.0, BetaQ=100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [04:26, 66.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ‚è±Ô∏è Time: 67.4s | üìè MED: 0.004996 | üìà HV: 1.690575\n",
      "      üèÜ New Best MED Found! Saved to: model/_Ex_7_2/best_trans_MED.pth\n",
      "\n",
      "   >>> Config 5/36: {'lr': 0.001, 'num_epochs': 500, 'num_partitions': 20, 'beta_C_0': 10, 'beta_Q_0': 5, 'rho_C': 1.03, 'rho_Q': 1.03, 'beta_C_max': 1000.0, 'beta_Q_max': 500.0}\n",
      "=== TRAIN HYPERNET (Algorithm 2-A: Monotonic Penalty) ===\n",
      "Constraint C: Start 10 -> Max 1000.0 (Rate 1.03)\n",
      "Constraint Q: Start 5 -> Max 500.0 (Rate 1.03)\n",
      "Epoch 0: Total=2.743 (Obj=0.5827, C=0.14885, Q=0.13432) || BetaC=10.3, BetaQ=5.2\n",
      "Epoch 100: Total=0.123 (Obj=0.1230, C=0.00000, Q=0.00000) || BetaC=198.0, BetaQ=99.0\n",
      "Epoch 200: Total=0.118 (Obj=0.1179, C=0.00000, Q=0.00000) || BetaC=1000.0, BetaQ=500.0\n",
      "Epoch 300: Total=0.117 (Obj=0.1168, C=0.00000, Q=0.00000) || BetaC=1000.0, BetaQ=500.0\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for model_name in models:\n",
    "    print(f\"\\nüîπ ƒêang train Model: {model_name} | ∆Øu ti√™n: {INDICATOR}\")\n",
    "    \n",
    "    # Kh·ªüi t·∫°o gi√° tr·ªã t·ªët nh·∫•t t√πy theo Indicator\n",
    "    if INDICATOR == \"MED\":\n",
    "        current_best_score = float('inf')  # MED t√¨m Min\n",
    "    else:\n",
    "        current_best_score = -1.0          # HV t√¨m Max\n",
    "        \n",
    "    current_best_config = None\n",
    "    \n",
    "    # T·∫°o l∆∞·ªõi tham s·ªë\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    param_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "    \n",
    "    for idx, params in tqdm(enumerate(param_combinations)):\n",
    "        print(f\"\\n   >>> Config {idx+1}/{len(param_combinations)}: {params}\")\n",
    "        \n",
    "        # 1. Init Model\n",
    "        if model_name == \"MLP\":\n",
    "            model = Hypernet_MLP(ray_hidden_dim=32, out_dim=dim_x, n_tasks=2).to(device)\n",
    "        else:\n",
    "            model = Hypernet_trans(ray_hidden_dim=32, out_dim=dim_x, n_tasks=2).to(device)\n",
    "        \n",
    "        # 2. Train (S·ª≠ d·ª•ng h√†m train_hypernet ƒë√£ c√≥ c·ªßa b·∫°n)\n",
    "        start_time = time.time()\n",
    "        trained_model = train_hypernet(\n",
    "            model, prob, z_star, \n",
    "            num_epochs=params['num_epochs'],\n",
    "            lr=params['lr'],\n",
    "            num_partitions=params['num_partitions'], \n",
    "            beta_C_0=params['beta_C_0'],\n",
    "            beta_C_max=params['beta_C_max'],\n",
    "            rho_C=params['rho_C'],\n",
    "            beta_Q_0=params['beta_Q_0'],\n",
    "            beta_Q_max=params['beta_Q_max'],\n",
    "            rho_Q=params['rho_Q'],\n",
    "            verbose=True \n",
    "        )\n",
    "        train_time = time.time() - start_time\n",
    "\n",
    "        # 3. ƒê√°nh gi√° ƒëa m·ª•c ti√™u\n",
    "        med, hv, pf_pred = evaluate_model_all(trained_model, prob, test_rays, pf_true, ref_point)\n",
    "        \n",
    "        # Ch·ªçn score ƒë·ªÉ so s√°nh d·ª±a tr√™n INDICATOR\n",
    "        score_to_compare = med if INDICATOR == \"MED\" else hv\n",
    "        \n",
    "        print(f\"      ‚è±Ô∏è Time: {train_time:.1f}s | üìè MED: {med:.6f} | üìà HV: {hv:.6f}\")\n",
    "\n",
    "        # 4. L∆∞u log\n",
    "        res = {\n",
    "            'model_type': model_name,\n",
    "            'config_id': idx,\n",
    "            'params': params,\n",
    "            'med': med,\n",
    "            'hv': hv,\n",
    "            'time': train_time\n",
    "        }\n",
    "        results.append(res)\n",
    "\n",
    "        # 5. C·∫≠p nh·∫≠t Best Model\n",
    "        is_best = False\n",
    "        if INDICATOR == \"MED\":\n",
    "            if score_to_compare < current_best_score:\n",
    "                current_best_score = score_to_compare\n",
    "                is_best = True\n",
    "        else: # INDICATOR == \"HV\"\n",
    "            if score_to_compare > current_best_score:\n",
    "                current_best_score = score_to_compare\n",
    "                is_best = True\n",
    "        \n",
    "        if is_best:\n",
    "            current_best_config = params\n",
    "            save_path = f\"{save_dir}/best_{model_name}_{INDICATOR}.pth\"\n",
    "            torch.save(trained_model.state_dict(), save_path)\n",
    "            print(f\"      üèÜ New Best {INDICATOR} Found! Saved to: {save_path}\")\n",
    "\n",
    "    print(f\"\\n‚úÖ Ho√†n th√†nh {model_name}. Best {INDICATOR}: {current_best_score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f3ce36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ca5987",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T15:50:16.149307Z",
     "start_time": "2025-12-29T15:50:16.149298Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\n=== T·ªîNG H·ª¢P K·∫æT QU·∫¢ ===\")\n",
    "df_results.sort_values(by=['score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502a94f1",
   "metadata": {},
   "source": [
    "# Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a749f703",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-12-27T17:14:12.067Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*40)\n",
    "print(f\"üèÜ BEST CONFIGURATION FOUND (IGD={best_igd:.4f})\")\n",
    "print(\"=\"*40)\n",
    "for k, v in best_config.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "# S·∫Øp x·∫øp k·∫øt qu·∫£ theo IGD\n",
    "sorted_results = sorted(results, key=lambda x: x['igd'])\n",
    "print(\"\\nTop 5 Configs:\")\n",
    "for i in range(min(5, len(sorted_results))):\n",
    "    r = sorted_results[i]\n",
    "    print(f\"Rank {i+1}: IGD={r['igd']:.4f} | Params={r['params']}\")\n",
    "\n",
    "# --- Plotting ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot Ground Truth\n",
    "if pf_true is not None:\n",
    "    plt.scatter(pf_true[:, 0], pf_true[:, 1], c='gray', alpha=0.5, label='Ground Truth', s=20)\n",
    "\n",
    "# Plot Best Prediction\n",
    "if best_pf_pred is not None:\n",
    "    plt.scatter(best_pf_pred[:, 0], best_pf_pred[:, 1], c='red', marker='x', label='Best Prediction', s=40)\n",
    "\n",
    "# Plot Ideal Point\n",
    "plt.scatter(z_star[0], z_star[1], c='green', marker='*', s=150, label='Ideal Point (z*)')\n",
    "\n",
    "plt.xlabel('f1')\n",
    "plt.ylabel('f2')\n",
    "plt.title(f'Pareto Front Approximation (Best IGD: {best_igd:.4f})')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccdf48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutdown -s -t 10800\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "245.895px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
