{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6db46434",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T17:26:39.103869Z",
     "start_time": "2025-12-28T17:26:37.469424Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import itertools\n",
    "import yaml\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize, Bounds\n",
    "from hypernet_MLP import Hypernet_MLP\n",
    "from hypernet_trans import Hypernet_trans\n",
    "from functions_hv_python3 import HyperVolume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ba3f98e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T17:26:39.120864Z",
     "start_time": "2025-12-28T17:26:39.105510Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=702):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "\n",
    "set_seed(702)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0fe6fdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T17:26:39.123654Z",
     "start_time": "2025-12-28T17:26:39.121877Z"
    }
   },
   "outputs": [],
   "source": [
    "case = case = \"_Ex_7_2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf49fd4",
   "metadata": {},
   "source": [
    "# Const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6ef3e46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T17:26:41.997819Z",
     "start_time": "2025-12-28T17:26:41.995236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee2227eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T17:26:42.166667Z",
     "start_time": "2025-12-28T17:26:42.163551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ t·∫£i ground truth Pareto front t·ª´: ../4_Pareto_front/test/_Ex_7_2/pf_dynamic_true.npy, Shape: (20, 2)\n"
     ]
    }
   ],
   "source": [
    "GROUND_TRUTH_FILE = f\"../4_Pareto_front/test/{case}/pf_dynamic_true.npy\" \n",
    "\n",
    "if os.path.exists(GROUND_TRUTH_FILE):\n",
    "    pf_true = np.load(GROUND_TRUTH_FILE)\n",
    "    print(f\"‚úÖ ƒê√£ t·∫£i ground truth Pareto front t·ª´: {GROUND_TRUTH_FILE}, Shape: {pf_true.shape}\")\n",
    "else:\n",
    "    print(f\"‚ùå KH√îNG t√¨m th·∫•y file ground truth t·∫°i: {GROUND_TRUTH_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419d020d",
   "metadata": {},
   "source": [
    "# Def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a40976c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T17:26:48.257480Z",
     "start_time": "2025-12-28T17:26:48.241772Z"
    }
   },
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from scipy.optimize import minimize            \n",
    "        \n",
    "class Projection:\n",
    "    def __init__(self, cons, bounds, dim, proj_type='euclid'):\n",
    "        self.cons = cons\n",
    "        self.bounds = bounds\n",
    "        self.dim = dim\n",
    "        self.proj_type = proj_type\n",
    "        \n",
    "        if self.proj_type == 'qplus':\n",
    "            self.objective_func = self._obj_positive_diff\n",
    "        elif self.proj_type == 'euclid':\n",
    "            self.objective_func = self._obj_l2_norm\n",
    "        else:\n",
    "            print(f\"Ph√©p chi·∫øu {self.objective_func} kh√¥ng c√†i ƒë·∫∑t, ch·ªçn 'qplus' ho·∫∑c 'euclid'\")\n",
    "\n",
    "    def _obj_l2_norm(self, x, y):\n",
    "        return np.sqrt(np.sum((x - y)**2))\n",
    "    \n",
    "    def _obj_positive_diff(self, x, y):\n",
    "        v = np.maximum(y - x, 0) \n",
    "        return np.sum(v**2)\n",
    "\n",
    "    def project(self, target_point):\n",
    "        init_point = np.random.rand(1, self.dim).tolist()[0]\n",
    "        \n",
    "        res = minimize(\n",
    "            self.objective_func,\n",
    "            init_point,\n",
    "            args=(target_point, ),\n",
    "            constraints=self.cons,\n",
    "            bounds=self.bounds,\n",
    "            options={'disp': False}\n",
    "        )\n",
    "        \n",
    "        optim_point = res.x\n",
    "        \n",
    "        if self.proj_type == 'qplus':\n",
    "            return target_point - np.maximum(target_point - optim_point, 0)\n",
    "        else:\n",
    "            return optim_point\n",
    "\n",
    "class Problem():\n",
    "    def __init__(self, f, dim_x, dim_y, proj_C, proj_Qplus):\n",
    "        self.f = f\n",
    "        self.dim_x = dim_x\n",
    "        self.dim_y = dim_y\n",
    "        self.proj_C = proj_C\n",
    "        self.proj_Qplus = proj_Qplus\n",
    "    \n",
    "    def objective_func(self, x):\n",
    "        vals = [func(x) for func in self.f]\n",
    "        return np.concatenate(vals)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d6f3d28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T17:26:48.719136Z",
     "start_time": "2025-12-28T17:26:48.714799Z"
    }
   },
   "outputs": [],
   "source": [
    "def f1(x):    return (x[0]**2 + x[1]**2)/50\n",
    "def f2(x):    return ((x[0] - 5)**2 + (x[1] - 5)**2)/50\n",
    "def f(x):    return np.array([\n",
    "    (x[0]**2 + x[1]**2)/50,\n",
    "    ((x[0] - 5)**2 + (x[1] - 5)**2)/50])\n",
    "#--------------- C --------------------#\n",
    "bounds_x = Bounds([0,0],[5, 5])\n",
    "\n",
    "#--------------- Q --------------------#\n",
    "def q1(y):    return 0.2**2 - (y[0] - 0.4)**2 - (y[1] - 0.4)**2\n",
    "\n",
    "def q_plus(y):\n",
    "    center = 0.4\n",
    "    radius_sq = 0.2**2  \n",
    "    dx = np.maximum(0, y[0] - center)\n",
    "    dy = np.maximum(0, y[1] - center)\n",
    "    return radius_sq - (dx**2 + dy**2)\n",
    "# H√†m d√πng cho Projection \n",
    "cons_C = ()\n",
    "dim_x = 2\n",
    "cons_Q = ({'type': 'ineq', 'fun' : q1,},)\n",
    "cons_Qplus = ({'type': 'ineq', 'fun': q_plus},)\n",
    "dim_y = 2\n",
    "# Setup Projections\n",
    "proj_C_handler = Projection(cons=cons_C, bounds=bounds_x, dim=dim_x, proj_type='euclid')\n",
    "proj_Q_handler = Projection(cons=cons_Q, bounds=None, dim=dim_y, proj_type='qplus')\n",
    "# Setup Problem\n",
    "prob = Problem(\n",
    "    f=[f1, f2], \n",
    "    dim_x=dim_x, dim_y=dim_y,\n",
    "    proj_C=proj_C_handler.project,\n",
    "    proj_Qplus=proj_Q_handler.project\n",
    ")\n",
    "z_star = np.array([0.0, 0.0])\n",
    "x_init = np.array([-10.0, -10.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95be6304",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T17:27:05.115024Z",
     "start_time": "2025-12-28T17:27:05.110797Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_objectives_single(functions, x_tensor):\n",
    "    vals = []\n",
    "    for func in functions:\n",
    "        val = func(x_tensor)\n",
    "        if not torch.is_tensor(val): val = torch.tensor(val, dtype=torch.float32, device=x_tensor.device)\n",
    "        vals.append(val)\n",
    "    return torch.stack(vals).reshape(-1)\n",
    "\n",
    "def calculate_mse_igd(pf_pred, pf_true):\n",
    "    if len(pf_pred) == 0: return np.inf\n",
    "    total_dist_sq = 0\n",
    "    # V·ªõi m·ªói ƒëi·ªÉm ground truth, t√¨m ƒëi·ªÉm d·ª± ƒëo√°n g·∫ßn nh·∫•t\n",
    "    for p_true in pf_true:\n",
    "        dists_sq = np.sum((pf_pred - p_true)**2, axis=1)\n",
    "        total_dist_sq += np.min(dists_sq)\n",
    "    return total_dist_sq / len(pf_true)\n",
    "\n",
    "def calculate_mse(pf_pred, pf_true):\n",
    "    pf_pred_ = np.array(pf_pred)\n",
    "    pf_true_ = np.array(pf_true)\n",
    "    \n",
    "    if pf_pred_.shape != pf_true_.shape:\n",
    "        print(f\"‚ö†Ô∏è Warning: Shape mismatch {pf_pred_.shape} vs {pf_true_.shape}. MSE c√≥ th·ªÉ kh√¥ng ch√≠nh x√°c.\")\n",
    "        return np.inf\n",
    "\n",
    "    return np.mean((pf_pred_ - pf_true_)**2)\n",
    "def calculate_hv_score(pareto_f, prob, ref_point):\n",
    "    \"\"\"T√≠nh Hypervolume, lo·∫°i b·ªè ƒëi·ªÉm vi ph·∫°m r√†ng bu·ªôc Q+\"\"\"\n",
    "    valid_points = []\n",
    "    tol = 1e-3\n",
    "    for point in pareto_f:\n",
    "        # Ki·ªÉm tra feasibility v·ªõi Q+\n",
    "        point_proj = prob.proj_Qplus(point)\n",
    "        dist_Q = np.linalg.norm(point - point_proj)\n",
    "        \n",
    "        # Ki·ªÉm tra n·∫±m trong v√πng Reference\n",
    "        is_dominated_by_ref = np.all(point < ref_point)\n",
    "        \n",
    "        if dist_Q < tol and is_dominated_by_ref:\n",
    "            valid_points.append(point.tolist())\n",
    "            \n",
    "    if len(valid_points) < 2: return 0.0\n",
    "    \n",
    "    hv = HyperVolume(ref_point)\n",
    "    return hv.compute(valid_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cc3790d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T17:27:07.151892Z",
     "start_time": "2025-12-28T17:27:07.143765Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_objectives_single(functions, x_tensor):\n",
    "    \"\"\"\n",
    "    H√†m ph·ª• tr·ª£: T√≠nh gi√° tr·ªã f1(x), f2(x) cho 1 m·∫´u x duy nh·∫•t.\n",
    "    \"\"\"\n",
    "    vals = []\n",
    "    for func in functions:\n",
    "        val = func(x_tensor)\n",
    "        if not torch.is_tensor(val):\n",
    "            val = torch.tensor(val, dtype=torch.float32)\n",
    "        vals.append(val)\n",
    "    return torch.stack(vals).reshape(-1)\n",
    "\n",
    "def train_hypernet(hypernet, prob, z_star, \n",
    "                   num_epochs=1000, \n",
    "                   lr=1e-3, \n",
    "                   num_partitions=100, \n",
    "                   lr_step_size=300, \n",
    "                   lr_gamma=0.5,\n",
    "                   # --- THAM S·ªê THU·∫¨T TO√ÅN 2-A (Monotonic Penalty) ---\n",
    "                   # C·∫£ hai ƒë·ªÅu TƒÇNG d·∫ßn ƒë·ªÉ ƒë·∫£m b·∫£o Feasibility\n",
    "                   beta_C_0=1.0,    # Gi√° tr·ªã kh·ªüi t·∫°o cho C\n",
    "                   beta_C_max=1000.0, # Gi√° tr·ªã t·ªëi ƒëa cho C\n",
    "                   rho_C=1.01,      # T·ª∑ l·ªá tƒÉng cho C (VD: 1.01 = +1%/step)\n",
    "                   \n",
    "                   beta_Q_0=1.0,    # Gi√° tr·ªã kh·ªüi t·∫°o cho Q (Algorithm 2-A: TƒÉng Q)\n",
    "                   beta_Q_max=1000.0, # Gi√° tr·ªã t·ªëi ƒëa cho Q\n",
    "                   rho_Q=1.01,      # T·ª∑ l·ªá tƒÉng cho Q\n",
    "                   verbose=True): \n",
    "    \n",
    "    # 1. Kh·ªüi t·∫°o\n",
    "    optimizer = optim.Adam(hypernet.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=lr_step_size, gamma=lr_gamma)\n",
    "    \n",
    "    # ƒê·∫£m b·∫£o z_star chu·∫©n shape\n",
    "    z_star_tensor = torch.tensor(z_star, dtype=torch.float32).view(1, -1)\n",
    "    \n",
    "    # Kh·ªüi t·∫°o h·ªá s·ªë ph·∫°t (Step 1 c·ªßa Alg 2-A)\n",
    "    beta_C = beta_C_0\n",
    "    beta_Q = beta_Q_0\n",
    "    \n",
    "    angle_step = (math.pi / 2) / num_partitions\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"=== TRAIN HYPERNET (Algorithm 2-A: Monotonic Penalty) ===\")\n",
    "        print(f\"Constraint C: Start {beta_C_0} -> Max {beta_C_max} (Rate {rho_C})\")\n",
    "        print(f\"Constraint Q: Start {beta_Q_0} -> Max {beta_Q_max} (Rate {rho_Q})\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        hypernet.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # --------------------------------------------------------\n",
    "        # 1. L·∫•y m·∫´u ph√¢n t·∫ßng (Stratified Sampling - Step 4,5 of Alg 2-A)\n",
    "        # --------------------------------------------------------\n",
    "        starts = torch.arange(num_partitions) * angle_step\n",
    "        noise = torch.rand(num_partitions) * angle_step\n",
    "        thetas = starts + noise \n",
    "        \n",
    "        r_batch_np = np.stack([np.cos(thetas.numpy()), np.sin(thetas.numpy())], axis=1)\n",
    "        r_tensor_batch = torch.tensor(r_batch_np, dtype=torch.float32)\n",
    "        \n",
    "        # --------------------------------------------------------\n",
    "        # 2. Lan truy·ªÅn xu√¥i & T√≠nh Loss (Step 8-18 of Alg 2-A)\n",
    "        # --------------------------------------------------------\n",
    "        \n",
    "        # Forward pass (Sequential ƒë·ªÉ tr√°nh l·ªói shape c·ªßa Hypernet)\n",
    "        x_pred_list = []\n",
    "        for i in range(num_partitions):\n",
    "            r_single = r_tensor_batch[i].unsqueeze(0)\n",
    "            x_single = hypernet(r_single)\n",
    "            x_pred_list.append(x_single)\n",
    "            \n",
    "        x_vec_batch = torch.cat(x_pred_list, dim=0) # Batch output\n",
    "        \n",
    "        # Loop t√≠nh Loss th√†nh ph·∫ßn (do Scipy projection kh√¥ng h·ªó tr·ª£ batch)\n",
    "        x_np_batch = x_vec_batch.detach().cpu().numpy()\n",
    "        loss_C_list = []\n",
    "        loss_Q_list = []\n",
    "        y_pred_list = []\n",
    "        \n",
    "        for i in range(num_partitions):\n",
    "            x_i_tensor = x_vec_batch[i].reshape(-1) \n",
    "            x_i_np = x_i_tensor.detach().cpu().numpy()\n",
    "            \n",
    "            # a. Loss C: ||x - P_C(x)||^2\n",
    "            x_proj_i_np = prob.proj_C(x_i_np)\n",
    "            x_proj_i_tensor = torch.tensor(x_proj_i_np, dtype=torch.float32)\n",
    "            loss_C_list.append(torch.sum((x_i_tensor - x_proj_i_tensor)**2))\n",
    "            \n",
    "            # b. F(x)\n",
    "            y_pred_i = evaluate_objectives_single(prob.f, x_i_tensor)\n",
    "            y_pred_list.append(y_pred_i)\n",
    "            \n",
    "            # c. Loss Q: ||y - P_Q+(y)||^2\n",
    "            y_i_np = y_pred_i.detach().cpu().numpy()\n",
    "            y_proj_i_np = prob.proj_Qplus(y_i_np)\n",
    "            y_proj_i_tensor = torch.tensor(y_proj_i_np, dtype=torch.float32)\n",
    "            loss_Q_list.append(torch.sum((y_pred_i - y_proj_i_tensor)**2))\n",
    "        \n",
    "        # T√≠nh trung b√¨nh Loss (Mean L_C, Mean L_Q)\n",
    "        y_pred_batch = torch.stack(y_pred_list)\n",
    "        L_bar_C = torch.mean(torch.stack(loss_C_list))\n",
    "        L_bar_Q = torch.mean(torch.stack(loss_Q_list))\n",
    "        \n",
    "        # --------------------------------------------------------\n",
    "        # 3. T√≠nh Loss M·ª•c ti√™u Chebyshev (Step 20-21 of Alg 2-A)\n",
    "        # --------------------------------------------------------\n",
    "        diff = y_pred_batch - z_star_tensor\n",
    "        weighted_diff = r_tensor_batch * diff\n",
    "        max_vals, _ = torch.max(weighted_diff, dim=1)\n",
    "        L_Obj = torch.mean(max_vals)\n",
    "        \n",
    "        # --------------------------------------------------------\n",
    "        # 4. T·ªïng h·ª£p v√† C·∫≠p nh·∫≠t (Step 24-27 of Alg 2-A)\n",
    "        # --------------------------------------------------------\n",
    "        # L_Total = L_Obj + Œ≤_C * L_C + Œ≤_Q * L_Q\n",
    "        total_loss = L_Obj + (beta_C * L_bar_C) + (beta_Q * L_bar_Q)\n",
    "        \n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # --------------------------------------------------------\n",
    "        # 5. C·∫≠p nh·∫≠t h·ªá s·ªë Ph·∫°t (Step 30-31 of Alg 2-A)\n",
    "        # --------------------------------------------------------\n",
    "        # C·∫£ hai h·ªá s·ªë ƒë·ªÅu TƒÇNG d·∫ßn\n",
    "        beta_C = min(beta_C_max, beta_C * rho_C)\n",
    "        beta_Q = min(beta_Q_max, beta_Q * rho_Q)\n",
    "        \n",
    "        # Logging\n",
    "        if verbose and epoch % 100 == 0:\n",
    "            current_lr = scheduler.get_last_lr()[0]\n",
    "            print(f\"Epoch {epoch}: Total={total_loss.item():.3f} \"\n",
    "                  f\"(Obj={L_Obj.item():.4f}, C={L_bar_C.item():.5f}, Q={L_bar_Q.item():.5f}) \"\n",
    "                  f\"|| BetaC={beta_C:.1f}, BetaQ={beta_Q:.1f}\")\n",
    "            \n",
    "    return hypernet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1a1fc1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T17:27:13.913841Z",
     "start_time": "2025-12-28T17:27:13.909632Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(hypernet, prob, test_rays, pf_true, metric_func):\n",
    "    hypernet.eval()\n",
    "    pf_pred = []\n",
    "    rays_tensor = torch.tensor(test_rays, dtype=torch.float32, device=device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Sequential infer to avoid shape issues\n",
    "        for i in range(len(rays_tensor)):\n",
    "            r_single = rays_tensor[i].unsqueeze(0)\n",
    "            x_raw = hypernet(r_single).squeeze().cpu().numpy()\n",
    "            \n",
    "            # Project to C for fair comparison\n",
    "            x_proj = prob.proj_C(x_raw)\n",
    "            val = [func(x_proj) for func in prob.f]\n",
    "            pf_pred.append(val)\n",
    "            \n",
    "    pf_pred = np.array(pf_pred)\n",
    "    score = metric_func(pf_pred, pf_true)\n",
    "    return score, pf_pred\n",
    "def evaluate_model_hv(hypernet, prob, test_rays, ref_point):\n",
    "    \"\"\"\n",
    "    ƒê√°nh gi√° model d·ª±a tr√™n ch·ªâ s·ªë Hypervolume (HV).\n",
    "    \"\"\"\n",
    "    hypernet.eval()\n",
    "    pf_pred = []\n",
    "    \n",
    "    # Chuy·ªÉn test rays l√™n device\n",
    "    rays_tensor = torch.tensor(test_rays, dtype=torch.float32, device=device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Sequential infer ƒë·ªÉ tr√°nh l·ªói shape c·ªßa model\n",
    "        for i in range(len(rays_tensor)):\n",
    "            r_single = rays_tensor[i].unsqueeze(0)\n",
    "            \n",
    "            # Forward pass\n",
    "            x_raw = hypernet(r_single).squeeze().cpu().numpy()\n",
    "            \n",
    "            # Chi·∫øu l√™n C (B·∫Øt bu·ªôc ƒë·ªÉ ƒë·∫£m b·∫£o feasibility ƒë·∫ßu v√†o)\n",
    "            x_proj = prob.proj_C(x_raw)\n",
    "            \n",
    "            # T√≠nh gi√° tr·ªã h√†m m·ª•c ti√™u\n",
    "            val = [func(x_proj) for func in prob.f]\n",
    "            pf_pred.append(val)\n",
    "            \n",
    "    pf_pred = np.array(pf_pred)\n",
    "    \n",
    "    # T√≠nh HV Score (S·ª≠ d·ª•ng h√†m ƒë√£ c√≥ t·ª´ b∆∞·ªõc tr∆∞·ªõc)\n",
    "    # L∆∞u √Ω: H√†m n√†y t·ª± l·ªçc b·ªè c√°c ƒëi·ªÉm vi ph·∫°m Q+\n",
    "    score = calculate_hv_score(pf_pred, prob, ref_point)\n",
    "    \n",
    "    return score, pf_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6563764",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d696f100",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T17:30:23.184223Z",
     "start_time": "2025-12-28T17:30:23.178385Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'lr': [1e-3],\n",
    "    'num_epochs': [500],\n",
    "    \n",
    "    'num_partitions': [20],\n",
    "    \n",
    "    # Tham s·ªë thu·∫≠t to√°n 2-A: TƒÉng d·∫ßn penalty\n",
    "    'beta_C_0': [1.0],\n",
    "    'beta_Q_0': [1.0],\n",
    "    'rho_C': [1.01, 1.05], \n",
    "    'rho_Q': [1.01, 1.05],\n",
    "    \n",
    "    # C·ªë ƒë·ªãnh Max ƒë·ªÉ tr√°nh grid qu√° l·ªõn \n",
    "    'beta_C_max': [1000.0],\n",
    "    'beta_Q_max': [1000.0]\n",
    "}\n",
    "\n",
    "config_path='../4_Pareto_front/config.yaml'\n",
    "with open(config_path, 'r') as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "test_rays = np.array(cfg['data']['test_ray'])\n",
    "ref_point = np.array([1.3927, 1.3927])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f727817a",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13f1aaf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T17:30:23.911769Z",
     "start_time": "2025-12-28T17:30:23.909777Z"
    }
   },
   "outputs": [],
   "source": [
    "models = [\"trans\", \"MLP\"]\n",
    "mode_tests = [\"HV\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7db2140",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T17:30:24.075952Z",
     "start_time": "2025-12-28T17:30:24.074058Z"
    }
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "best_scores_tracker = {}\n",
    "save_dir = f\"model/{case}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e51f15b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T17:38:43.065324Z",
     "start_time": "2025-12-28T17:30:24.230512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ ƒêang train Model: trans\n",
      "\n",
      "   >>> Config 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7036\\519494600.py:28: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
      "  res = minimize(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ‚è±Ô∏è Time: 65.32s | üìà HV Score: 1.675372\n",
      "      üèÜ New Best Found! Saved to: model/_Ex_7_2/best_trans_HV.pth\n",
      "\n",
      "   >>> Config 2/4\n",
      "      ‚è±Ô∏è Time: 64.38s | üìà HV Score: 1.677715\n",
      "      üèÜ New Best Found! Saved to: model/_Ex_7_2/best_trans_HV.pth\n",
      "\n",
      "   >>> Config 3/4\n",
      "      ‚è±Ô∏è Time: 65.25s | üìà HV Score: 1.675509\n",
      "\n",
      "   >>> Config 4/4\n",
      "      ‚è±Ô∏è Time: 65.22s | üìà HV Score: 1.687903\n",
      "      üèÜ New Best Found! Saved to: model/_Ex_7_2/best_trans_HV.pth\n",
      "\n",
      "‚úÖ Ho√†n th√†nh trans. Best HV: 1.687903\n",
      "   Best Config: {'lr': 0.001, 'num_epochs': 500, 'num_partitions': 20, 'beta_C_0': 1.0, 'beta_Q_0': 1.0, 'rho_C': 1.05, 'rho_Q': 1.05, 'beta_C_max': 1000.0, 'beta_Q_max': 1000.0}\n",
      "\n",
      "üîπ ƒêang train Model: MLP\n",
      "\n",
      "   >>> Config 1/4\n",
      "      ‚è±Ô∏è Time: 58.87s | üìà HV Score: 1.689825\n",
      "      üèÜ New Best Found! Saved to: model/_Ex_7_2/best_MLP_HV.pth\n",
      "\n",
      "   >>> Config 2/4\n",
      "      ‚è±Ô∏è Time: 59.63s | üìà HV Score: 1.683531\n",
      "\n",
      "   >>> Config 3/4\n",
      "      ‚è±Ô∏è Time: 59.62s | üìà HV Score: 1.679540\n",
      "\n",
      "   >>> Config 4/4\n",
      "      ‚è±Ô∏è Time: 59.61s | üìà HV Score: 1.684209\n",
      "\n",
      "‚úÖ Ho√†n th√†nh MLP. Best HV: 1.689825\n",
      "   Best Config: {'lr': 0.001, 'num_epochs': 500, 'num_partitions': 20, 'beta_C_0': 1.0, 'beta_Q_0': 1.0, 'rho_C': 1.01, 'rho_Q': 1.01, 'beta_C_max': 1000.0, 'beta_Q_max': 1000.0}\n"
     ]
    }
   ],
   "source": [
    "for model_name in models:\n",
    "    print(f\"\\nüîπ ƒêang train Model: {model_name}\")\n",
    "    \n",
    "    # V·ªõi HV, ta t√¨m MAX (ban ƒë·∫ßu set l√† -1 ho·∫∑c 0)\n",
    "    current_best_score = -1.0 \n",
    "    current_best_config = None\n",
    "    \n",
    "    # T·∫°o l∆∞·ªõi tham s·ªë\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    param_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "    \n",
    "    for idx, params in enumerate(param_combinations):\n",
    "        print(f\"\\n   >>> Config {idx+1}/{len(param_combinations)}\")\n",
    "        \n",
    "        # 1. Init Model\n",
    "        if model_name == \"MLP\":\n",
    "            model = Hypernet_MLP(ray_hidden_dim=32, out_dim=dim_x, n_tasks=2)\n",
    "        else:\n",
    "            model = Hypernet_trans(ray_hidden_dim=32, out_dim=dim_x, n_tasks=2)\n",
    "        \n",
    "        # 2. Train (Algorithm 2-A: Monotonic Penalty)\n",
    "        start_time = time.time()\n",
    "        # L∆∞u √Ω: T·∫Øt verbose=True ƒë·ªÉ log g·ªçn h∆°n n·∫øu ch·∫°y nhi·ªÅu config\n",
    "        trained_model = train_hypernet(\n",
    "            model, prob, z_star, \n",
    "            num_epochs=params['num_epochs'],\n",
    "            lr=params['lr'],\n",
    "            num_partitions=params['num_partitions'], \n",
    "            # Param ph·∫°t ƒë·ªông\n",
    "            beta_C_0=params['beta_C_0'],\n",
    "            beta_C_max=params['beta_C_max'],\n",
    "            rho_C=params['rho_C'],\n",
    "            beta_Q_0=params['beta_Q_0'],\n",
    "            beta_Q_max=params['beta_Q_max'],\n",
    "            rho_Q=params['rho_Q'],\n",
    "            verbose=False \n",
    "        )\n",
    "        train_time = time.time() - start_time\n",
    "\n",
    "        # 3. Evaluate theo HV\n",
    "        # Kh√¥ng c·∫ßn pf_true (ground truth) v√¨ HV l√† metric unsupervised\n",
    "        score, pf_pred = evaluate_model_hv(trained_model, prob, test_rays, ref_point)\n",
    "\n",
    "        print(f\"      ‚è±Ô∏è Time: {train_time:.2f}s | üìà HV Score: {score:.6f}\")\n",
    "\n",
    "        # 4. Save result\n",
    "        res = {\n",
    "            'model_type': model_name,\n",
    "            'metric_type': \"HV\",\n",
    "            'config_id': idx,\n",
    "            'params': params,\n",
    "            'score': score,\n",
    "            'time': train_time\n",
    "        }\n",
    "        results.append(res)\n",
    "\n",
    "        # 5. Update Best (MAXIMIZATION)\n",
    "        if score > current_best_score:\n",
    "            current_best_score = score\n",
    "            current_best_config = params\n",
    "            \n",
    "            save_path = f\"{save_dir}/best_{model_name}_HV.pth\"\n",
    "            torch.save(trained_model.state_dict(), save_path)\n",
    "            print(f\"      üèÜ New Best Found! Saved to: {save_path}\")\n",
    "\n",
    "    print(f\"\\n‚úÖ Ho√†n th√†nh {model_name}. Best HV: {current_best_score:.6f}\")\n",
    "    print(f\"   Best Config: {current_best_config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10ca5987",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T17:41:04.263565Z",
     "start_time": "2025-12-28T17:41:04.255968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== T·ªîNG H·ª¢P K·∫æT QU·∫¢ ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>metric_type</th>\n",
       "      <th>config_id</th>\n",
       "      <th>params</th>\n",
       "      <th>score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLP</td>\n",
       "      <td>HV</td>\n",
       "      <td>0</td>\n",
       "      <td>{'lr': 0.001, 'num_epochs': 500, 'num_partitio...</td>\n",
       "      <td>1.689825</td>\n",
       "      <td>58.870755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trans</td>\n",
       "      <td>HV</td>\n",
       "      <td>3</td>\n",
       "      <td>{'lr': 0.001, 'num_epochs': 500, 'num_partitio...</td>\n",
       "      <td>1.687903</td>\n",
       "      <td>65.224389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLP</td>\n",
       "      <td>HV</td>\n",
       "      <td>3</td>\n",
       "      <td>{'lr': 0.001, 'num_epochs': 500, 'num_partitio...</td>\n",
       "      <td>1.684209</td>\n",
       "      <td>59.613948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP</td>\n",
       "      <td>HV</td>\n",
       "      <td>1</td>\n",
       "      <td>{'lr': 0.001, 'num_epochs': 500, 'num_partitio...</td>\n",
       "      <td>1.683531</td>\n",
       "      <td>59.629263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLP</td>\n",
       "      <td>HV</td>\n",
       "      <td>2</td>\n",
       "      <td>{'lr': 0.001, 'num_epochs': 500, 'num_partitio...</td>\n",
       "      <td>1.679540</td>\n",
       "      <td>59.623288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trans</td>\n",
       "      <td>HV</td>\n",
       "      <td>1</td>\n",
       "      <td>{'lr': 0.001, 'num_epochs': 500, 'num_partitio...</td>\n",
       "      <td>1.677715</td>\n",
       "      <td>64.376963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trans</td>\n",
       "      <td>HV</td>\n",
       "      <td>2</td>\n",
       "      <td>{'lr': 0.001, 'num_epochs': 500, 'num_partitio...</td>\n",
       "      <td>1.675509</td>\n",
       "      <td>65.247506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trans</td>\n",
       "      <td>HV</td>\n",
       "      <td>0</td>\n",
       "      <td>{'lr': 0.001, 'num_epochs': 500, 'num_partitio...</td>\n",
       "      <td>1.675372</td>\n",
       "      <td>65.324842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_type metric_type  config_id  \\\n",
       "4        MLP          HV          0   \n",
       "3      trans          HV          3   \n",
       "7        MLP          HV          3   \n",
       "5        MLP          HV          1   \n",
       "6        MLP          HV          2   \n",
       "1      trans          HV          1   \n",
       "2      trans          HV          2   \n",
       "0      trans          HV          0   \n",
       "\n",
       "                                              params     score       time  \n",
       "4  {'lr': 0.001, 'num_epochs': 500, 'num_partitio...  1.689825  58.870755  \n",
       "3  {'lr': 0.001, 'num_epochs': 500, 'num_partitio...  1.687903  65.224389  \n",
       "7  {'lr': 0.001, 'num_epochs': 500, 'num_partitio...  1.684209  59.613948  \n",
       "5  {'lr': 0.001, 'num_epochs': 500, 'num_partitio...  1.683531  59.629263  \n",
       "6  {'lr': 0.001, 'num_epochs': 500, 'num_partitio...  1.679540  59.623288  \n",
       "1  {'lr': 0.001, 'num_epochs': 500, 'num_partitio...  1.677715  64.376963  \n",
       "2  {'lr': 0.001, 'num_epochs': 500, 'num_partitio...  1.675509  65.247506  \n",
       "0  {'lr': 0.001, 'num_epochs': 500, 'num_partitio...  1.675372  65.324842  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\n=== T·ªîNG H·ª¢P K·∫æT QU·∫¢ ===\")\n",
    "df_results.sort_values(by=['score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502a94f1",
   "metadata": {},
   "source": [
    "# Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a749f703",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-12-27T17:14:12.067Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*40)\n",
    "print(f\"üèÜ BEST CONFIGURATION FOUND (IGD={best_igd:.4f})\")\n",
    "print(\"=\"*40)\n",
    "for k, v in best_config.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "# S·∫Øp x·∫øp k·∫øt qu·∫£ theo IGD\n",
    "sorted_results = sorted(results, key=lambda x: x['igd'])\n",
    "print(\"\\nTop 5 Configs:\")\n",
    "for i in range(min(5, len(sorted_results))):\n",
    "    r = sorted_results[i]\n",
    "    print(f\"Rank {i+1}: IGD={r['igd']:.4f} | Params={r['params']}\")\n",
    "\n",
    "# --- Plotting ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot Ground Truth\n",
    "if pf_true is not None:\n",
    "    plt.scatter(pf_true[:, 0], pf_true[:, 1], c='gray', alpha=0.5, label='Ground Truth', s=20)\n",
    "\n",
    "# Plot Best Prediction\n",
    "if best_pf_pred is not None:\n",
    "    plt.scatter(best_pf_pred[:, 0], best_pf_pred[:, 1], c='red', marker='x', label='Best Prediction', s=40)\n",
    "\n",
    "# Plot Ideal Point\n",
    "plt.scatter(z_star[0], z_star[1], c='green', marker='*', s=150, label='Ideal Point (z*)')\n",
    "\n",
    "plt.xlabel('f1')\n",
    "plt.ylabel('f2')\n",
    "plt.title(f'Pareto Front Approximation (Best IGD: {best_igd:.4f})')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccdf48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutdown -s -t 10800\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
